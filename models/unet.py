import torch
import torch.nn as nn

from layers.vgg import VGG16
from layers.up_sampling import unetup
from torchsummary import summary

class Unet(nn.Module):
    def __init__(self, num_classes=21, in_channels=3, pretrained=False):
        super(Unet, self).__init__()
        self.vgg = VGG16(pretrained=pretrained, in_channels=in_channels)
        in_filters = [192, 384, 768, 1024]
        out_filters = [64, 128, 256, 512]
        # upsampling
        # 64,64,512
        self.up_concat4 = unetup(in_filters[3], out_filters[3])
        # 128,128,256
        self.up_concat3 = unetup(in_filters[2], out_filters[2])
        # 256,256,128
        self.up_concat2 = unetup(in_filters[1], out_filters[1])
        # 512,512,64
        self.up_concat1 = unetup(in_filters[0], out_filters[0])

        # final conv (without any concat)
        self.final = nn.Conv2d(out_filters[0], num_classes, 1)

    def forward(self, inputs):
        feat1 = self.vgg.features[:4](inputs)
        feat2 = self.vgg.features[4:9](feat1)
        feat3 = self.vgg.features[9:16](feat2)
        feat4 = self.vgg.features[16:23](feat3)
        feat5 = self.vgg.features[23:-1](feat4)

        up4 = self.up_concat4(feat4, feat5)
        up3 = self.up_concat3(feat3, up4)
        up2 = self.up_concat2(feat2, up3)
        up1 = self.up_concat1(feat1, up2)

        final = self.final(up1)

        return final

    def _initialize_weights(self, *stages):
        for modules in stages:
            for module in modules.modules():
                if isinstance(module, nn.Conv2d):
                    nn.init.kaiming_normal_(module.weight)
                    if module.bias is not None:
                        module.bias.data.zero_()
                elif isinstance(module, nn.BatchNorm2d):
                    module.weight.data.fill_(1)
                    module.bias.data.zero_()

if __name__ == "__main__":
    NUM_CLASSES = 21
    inputs_size = [512, 512, 3]
    pretrained = False
    model = Unet(num_classes=NUM_CLASSES, in_channels=inputs_size[-1], pretrained=pretrained).train()

    # print(model)
    summary(model, input_size=[(3, 512, 512)], batch_size=1, device="cpu")
    # X = torch.randn(size=(1, 3, 512, 512))
    # out = model(X)
    # print(out.shape)